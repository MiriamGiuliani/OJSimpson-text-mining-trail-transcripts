{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and delete **blank lines** and **lines not containing dialogs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\miria\\\\OneDrive - Universita Cattolica Sacro Cuore - ICATT\\\\INFORMATION RETRIVAL AND TEXT MINING\\\\project\\\\MiriamGiuliani_practicalassignment\\\\github\\\\py_scripts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\miria\\\\OneDrive - Universita Cattolica Sacro Cuore - ICATT\\\\INFORMATION RETRIVAL AND TEXT MINING\\\\project\\\\MiriamGiuliani_practicalassignment\\\\github\\\\py_scripts')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_functions import remove_html_tags, preprocessing_transctipts_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>speech</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  speech  date  time\n",
       "0       0       0     0     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'person': [0], 'speech': [0],  'date': [0], 'time': [0]}\n",
    "df = pd.DataFrame(mydict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocessing_transctipts_text() missing 1 required positional argument: 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7d9624a1c2ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreprocessing_transctipts_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: preprocessing_transctipts_text() missing 1 required positional argument: 'filename'"
     ]
    }
   ],
   "source": [
    "directory = os.getcwd()\n",
    "preprocessing_transctipts_text(directory, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if fnmatch.fnmatch(filename, 'jan*.txt'):\n",
    "        print(filename)\n",
    "        fh = open(filename, \"r\")\n",
    "        content_html = fh.read()\n",
    "        content_html = remove_html_tags(content_html)\n",
    "        content_html = content_html.upper()\n",
    "        fh.close()\n",
    "                \n",
    "        fh = open(\"text_notags.txt\", \"w\")\n",
    "        fh.write(content_html)\n",
    "        fh.close()\n",
    "\n",
    "        fh = open(\"text_notags.txt\", \"r\")\n",
    "        lines = fh.readlines()\n",
    "        fh.close()\n",
    "\n",
    "                # Weed out blank lines with filter\n",
    "        lines = filter(lambda x: not x.isspace(), lines)\n",
    "        lines = filter(lambda x: not x.startswith('('), lines)\n",
    "                # Write\n",
    "        fh = open(\"noblankbrack.txt\", \"w\")\n",
    "        fh.write(\"\".join(lines))\n",
    "        fh.close()\n",
    "\n",
    "        # Separate dialogs and description\n",
    "        fh = open('noblankbrack.txt', 'r')\n",
    "        content = fh.read()\n",
    "        dialogs = content.split('SUPERIOR COURT OF THE STATE OF CALIFORNIA')[0]\n",
    "        description = content.split('SUPERIOR COURT OF THE STATE OF CALIFORNIA')[1]\n",
    "        description\n",
    "        fh.close()\n",
    "\n",
    "        fh = open(\"dialogs.txt\", \"w\")\n",
    "        fh.write(dialogs)\n",
    "        fh.close()\n",
    "        fh = open(\"description.txt\", \"w\")\n",
    "        fh.write(description)\n",
    "        fh.close()\n",
    "\n",
    "        # Eliminate spaces within paragraph referred to the\n",
    "        # same person talking\n",
    "        fh = open(\"dialogs.txt\", \"r\")\n",
    "        lines_2 = fh.readlines()\n",
    "        fh.close()\n",
    "\n",
    "        new_text = list()\n",
    "        for index, line in enumerate(lines_2):\n",
    "            if index < len(lines_2)-1:\n",
    "                next_line = lines_2[index + 1]\n",
    "                if not next_line.startswith((\"#\")):\n",
    "                    modified_line = line.strip('\\n')\n",
    "                    new_text.append(modified_line)\n",
    "                else:\n",
    "                    new_text.append(line)\n",
    "        last_line = lines_2[len(lines_2)-1]    \n",
    "        new_text.append(last_line)\n",
    "\n",
    "        my_file = open(\"nospaces.txt\", \"w\")\n",
    "        new_file_contents = \"\".join(new_text)\n",
    "        my_file.write(new_file_contents)\n",
    "        my_file.close()\n",
    "\n",
    "        # Isolate the person speaking and her/his speech\n",
    "        with open('nospaces.txt', \"r\") as a_file:\n",
    "            person = list()\n",
    "            speeches = list()\n",
    "            for line in a_file:\n",
    "                mymatch = re.search(r'\\#.*?\\: ', line)\n",
    "                if mymatch:\n",
    "                    stripped_line = mymatch.group(0)\n",
    "                    p = line.split(stripped_line)[0]\n",
    "                    s = line.split(stripped_line)[1]\n",
    "                    person.append(stripped_line)\n",
    "                    speeches.append(s)\n",
    "\n",
    "        # Create a data frame\n",
    "        mydict = {'person': person, 'speech': speeches}\n",
    "        df1 = pd.DataFrame(mydict)\n",
    "\n",
    "        # Isolate date and time from the first row (i.e. introduction of the transcript)\n",
    "        date_search = re.search(r\"(([ADFJMNOS]\\w*)\\s[\\d]{1,2},\\s[\\d]{4}\\s)|(([ADFJMNOS]\\w*)\\s[\\d]{1,2}\\s[\\d]{4}\\s)\", df1.iloc[0,0])\n",
    "        time_search = re.search(r\"([\\d]{1,2}:[\\d]{1,2}\\s(A.M.|P.M.))\", df1.iloc[0,0])\n",
    "        date = date_search.group(1)\n",
    "        time = time_search.group(1)\n",
    "        # Add to df\n",
    "        df1['date'] = date \n",
    "        df1['time'] = time\n",
    "        ncol = df1.shape[0]\n",
    "        \n",
    "        new_row = {'person': 'DESCRIPTION', 'speech': description, 'date': date, 'time': time}\n",
    "        df1.append(new_row, ignore_index = True)\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Manage witness questioning: SUBSTITUTE 'A: ' WITH THE WITNESS NAME\n",
    "        nrow = df1.shape[0]\n",
    "\n",
    "        # find lines where the match occurs\n",
    "        match_a1 = 'CALLED AS A WITNESS BY'\n",
    "        match_a2 = 'THE WITNESS ON THE STAND AT THE TIME'\n",
    "        match_a3 = 'HAVING BEEN PREVIOUSLY SWORN'\n",
    "        case_w = 0\n",
    "        # Case 123: some witnesses are interrogated for the first time and others for the second time (resumed) and others are from previous days\n",
    "        if df1['speech'].str.contains(match_a1).any() and df1['speech'].str.contains(match_a2).any() and df1['speech'].str.contains(match_a3).any():\n",
    "            matching_points_a1 = df1[df1[\"speech\"].str.contains(match_a1)]\n",
    "            matching_indexes_a1 = list(matching_points_a1.index)\n",
    "            matching_points_a2 = df1[df1[\"speech\"].str.contains(match_a2)]\n",
    "            matching_indexes_a2 = list(matching_points_a2.index)\n",
    "            matching_points_a3 = df1[df1[\"speech\"].str.contains(match_a3)]\n",
    "            matching_indexes_a3 = list(matching_points_a3.index) \n",
    "            matching_indexes_a1.extend(matching_indexes_a2 + matching_indexes_a3)\n",
    "            matching_indexes_a1.sort() \n",
    "            matching_indexes_all_a = matching_indexes_a1.copy()\n",
    "            case_w = 123\n",
    "        # Case 12: some witnesses are interrogated for the first time and others for the second time (resumed)\n",
    "        elif df1['speech'].str.contains(match_a1).any() and df1['speech'].str.contains(match_a2).any():\n",
    "            matching_points_a1 = df1[df1[\"speech\"].str.contains(match_a1)]\n",
    "            matching_indexes_a1 = list(matching_points_a1.index)\n",
    "            matching_points_a2 = df1[df1[\"speech\"].str.contains(match_a2)]\n",
    "            matching_indexes_a2 = list(matching_points_a2.index) \n",
    "            matching_indexes_a1.extend(matching_indexes_a2)\n",
    "            matching_indexes_a1.sort() \n",
    "            matching_indexes_all_a = matching_indexes_a1.copy()\n",
    "            case_w = 12\n",
    "        # Case 13: some witnesses are interrogated for the first time and others from previous days\n",
    "        elif df1['speech'].str.contains(match_a1).any() and df1['speech'].str.contains(match_a3).any():\n",
    "            matching_points_a1 = df1[df1[\"speech\"].str.contains(match_a1)]\n",
    "            matching_indexes_a1 = list(matching_points_a1.index)\n",
    "            matching_points_a3 = df1[df1[\"speech\"].str.contains(match_a3)]\n",
    "            matching_indexes_a3 = list(matching_points_a3.index) \n",
    "            matching_indexes_a1.extend(matching_indexes_a3)\n",
    "            matching_indexes_a1.sort() \n",
    "            matching_indexes_all_a = matching_indexes_a1.copy()\n",
    "            case_w = 13\n",
    "        # Case 23: some witnesses are interrogated for the second time, same day and others from previous days\n",
    "        elif df1['speech'].str.contains(match_a2).any() and df1['speech'].str.contains(match_a3).any():\n",
    "            matching_points_a2 = df1[df1[\"speech\"].str.contains(match_a2)]\n",
    "            matching_indexes_a2 = list(matching_points_a2.index)\n",
    "            matching_points_a3 = df1[df1[\"speech\"].str.contains(match_a3)]\n",
    "            matching_indexes_a3 = list(matching_points_a3.index) \n",
    "            matching_indexes_a2.extend(matching_indexes_a3)\n",
    "            matching_indexes_a2.sort() \n",
    "            matching_indexes_all_a = matching_indexes_a2.copy()\n",
    "            case_w = 23\n",
    "        # Case 1: the witnesses are all interrogated for the first time\n",
    "        elif df1['speech'].str.contains(match_a1).any():\n",
    "            matching_points_a1 = df1[df1[\"speech\"].str.contains(match_a1)]\n",
    "            matching_indexes_a1 = list(matching_points_a1.index)\n",
    "            matching_indexes_all_a = matching_indexes_a1.copy()\n",
    "            case_w = 1\n",
    "        # Case 2: the witnesses are all interrogated for the second time within same day\n",
    "        elif df1['speech'].str.contains(match_a2).any():\n",
    "            matching_points_a2 = df1[df1[\"speech\"].str.contains(match_a2)]\n",
    "            matching_indexes_a2 = list(matching_points_a2.index)\n",
    "            matching_indexes_all_a = matching_indexes_a2.copy()\n",
    "            case_w = 2\n",
    "        # Case 3: the witnesses are all from previous days\n",
    "        elif df1['speech'].str.contains(match_a3).any():\n",
    "            matching_points_a3 = df1[df1[\"speech\"].str.contains(match_a3)]\n",
    "            matching_indexes_a3 = list(matching_points_a3.index)\n",
    "            matching_indexes_all_a = matching_indexes_a3.copy()\n",
    "            case_w = 3\n",
    "\n",
    "        # Create an empty list to store the name of the witnesses       \n",
    "        witnesses = list()\n",
    "        if case_w!=0:\n",
    "\n",
    "        # Substitute 'A:' with the name of the witness testifying\n",
    "            for i in range(0, len(matching_indexes_all_a)):\n",
    "                # CASE 123\n",
    "                if case_w == 123: \n",
    "                    # Retrieve the name of the witness and add it to the witness list\n",
    "                    if matching_indexes_all_a[i] in matching_indexes_a2:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"THE WITNESS ON THE STAND\")[0]\n",
    "                    elif matching_indexes_all_a[i] in matching_indexes_a3:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"HAVING BEEN PREVIOUSLY SWORN\")[0]\n",
    "                    else:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"CALLED AS A WITNESS BY\")[0]\n",
    "\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    # Substitute 'A: ' with the name of the witness\n",
    "                    if i < (len(matching_indexes_all_a) - 1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESSS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else: # if i corresponds to the last witness interrogation of the day\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name \n",
    "                # CASE 12\n",
    "                elif case_w == 12: \n",
    "                    # Retrieve the name of the witness and add it to the witness list\n",
    "                    if matching_indexes_all_a[i] in matching_indexes_a2:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"THE WITNESS ON THE STAND\")[0]\n",
    "                    else:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"CALLED AS A WITNESS BY\")[0]\n",
    "\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    # Substitute 'A: ' with the name of the witness\n",
    "                    if i < (len(matching_indexes_all_a) - 1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESSS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else: # if i corresponds to the last witness interrogation of the day\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                # CASE 13\n",
    "                elif case_w == 13: \n",
    "                    # Retrieve the name of the witness and add it to the witness list\n",
    "                    if matching_indexes_all_a[i] in matching_indexes_a3:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"HAVING BEEN PREVIOUSLY SWORN\")[0]\n",
    "                    else:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"CALLED AS A WITNESS BY\")[0]\n",
    "\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    # Substitute 'A: ' with the name of the witness\n",
    "                    if i < (len(matching_indexes_all_a) - 1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESSS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else: # if i corresponds to the last witness interrogation of the day\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                # CASE 23\n",
    "                elif case_w == 23: \n",
    "                    # Retrieve the name of the witness and add it to the witness list\n",
    "                    if matching_indexes_all_a[i] in matching_indexes_a3:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"HAVING BEEN PREVIOUSLY SWORN\")[0]\n",
    "                    else:\n",
    "                        before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"THE WITNESS ON THE STAND\")[0]\n",
    "\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    # Substitute 'A: ' with the name of the witness\n",
    "                    if i < (len(matching_indexes_all_a) - 1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESSS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else: # if i corresponds to the last witness interrogation of the day\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "\n",
    "                # CASE 1\n",
    "                elif case_w == 1:\n",
    "                    before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"CALLED AS A WITNESS BY\")[0]\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    if i < (len(matching_indexes_all_a)-1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else:\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                # CASE 2\n",
    "                elif case_w == 2:\n",
    "                    before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"THE WITNESS ON THE STAND\")[0]\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    if i < (len(matching_indexes_all_a)-1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else:\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                # CASE 3\n",
    "                elif case_w == 3:\n",
    "                    before_match = df1.iloc[matching_indexes_all_a[i], 1].split(\"HAVING BEEN PREVIOUSLY SWORN\")[0]\n",
    "                    witness_name = before_match.split()[-1:]\n",
    "                    witnesses.append(witness_name)\n",
    "                    if i < (len(matching_indexes_all_a)-1):\n",
    "                        for row in range(matching_indexes_all_a[i], matching_indexes_all_a[i + 1]):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "                    else:\n",
    "                        for row in range(matching_indexes_all_a[i], nrow):\n",
    "                            if df1.iloc[row, 0] == '#A: ' or df1.iloc[row, 0] == '#THE WITNESS: ':\n",
    "                                df1.iloc[row, df1.columns.get_loc('person')] = witness_name\n",
    "# -------------------------------------------------------------------------------------------------                        \n",
    "        \n",
    "        # Substitute 'Q:' with the name of the attorney questioning\n",
    "        match_1 = 'CROSS-EXAMINATIONBY'\n",
    "        match_2 = 'DIRECT EXAMINATIONBY'\n",
    "        match_3 = 'CROSS-EXAMINATION \\(RESUMED\\)BY'\n",
    "        match_4 = 'DIRECT EXAMINATION \\(RESUMED\\)BY'\n",
    "        #---------------------------------------------\n",
    "        # Define all possible combinations (14)\n",
    "        case = 0\n",
    "        if df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_3).any() and df1['speech'].str.contains(match_4).any(): \n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index) \n",
    "            matching_indexes_1.extend(matching_indexes_2+ matching_indexes_3 + matching_indexes_4)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy()\n",
    "            case = 1234\n",
    "        elif df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_3).any() and df1['speech'].str.contains(match_4).any():\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_2.extend(matching_indexes_3 + matching_indexes_4)\n",
    "            matching_indexes_2.sort() \n",
    "            matching_indexes_all = matching_indexes_2.copy() \n",
    "            case = 234\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_3).any() and df1['speech'].str.contains(match_4).any(): \n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_1.extend(matching_indexes_3 + matching_indexes_4)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy()\n",
    "            case = 134\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_4).any(): \n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_1.extend(matching_indexes_2 + matching_indexes_4)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy()\n",
    "            case = 124\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_3).any(): \n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_indexes_1.extend(matching_indexes_2+ matching_indexes_3)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy()\n",
    "            case = 123\n",
    "        elif df1['speech'].str.contains(match_3).any() and df1['speech'].str.contains(match_4).any():\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_3.extend(matching_indexes_4)\n",
    "            matching_indexes_3.sort() \n",
    "            matching_indexes_all = matching_indexes_3.copy() \n",
    "            case = 34\n",
    "        elif df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_4).any():\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_2.extend(matching_indexes_4)\n",
    "            matching_indexes_2.sort() \n",
    "            matching_indexes_all = matching_indexes_2.copy() \n",
    "            case = 24\n",
    "        elif df1['speech'].str.contains(match_2).any() and df1['speech'].str.contains(match_3).any():\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_indexes_2.extend(matching_indexes_3)\n",
    "            matching_indexes_2.sort() \n",
    "            matching_indexes_all = matching_indexes_2.copy()  \n",
    "            case = 23\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_4).any():\n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_1.extend(matching_indexes_4)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy() \n",
    "            case = 14\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_3).any():\n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_indexes_1.extend(matching_indexes_3)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy() \n",
    "            case = 13\n",
    "        elif df1['speech'].str.contains(match_1).any() and df1['speech'].str.contains(match_2).any():\n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_indexes_1.extend(matching_indexes_2)\n",
    "            matching_indexes_1.sort() \n",
    "            matching_indexes_all = matching_indexes_1.copy() \n",
    "            case = 12\n",
    "        elif df1['speech'].str.contains(match_1).any():\n",
    "            matching_points_1 = df1[df1[\"speech\"].str.contains(match_1)]\n",
    "            matching_indexes_1 = list(matching_points_1.index)\n",
    "            matching_indexes_all = matching_indexes_1.copy()\n",
    "            case = 1\n",
    "        elif df1['speech'].str.contains(match_2).any():\n",
    "            matching_points_2 = df1[df1[\"speech\"].str.contains(match_2)]\n",
    "            matching_indexes_2 = list(matching_points_2.index)\n",
    "            matching_indexes_all = matching_indexes_2.copy() \n",
    "            case = 2\n",
    "        elif df1['speech'].str.contains(match_3).any():\n",
    "            matching_points_3 = df1[df1[\"speech\"].str.contains(match_3)]\n",
    "            matching_indexes_3 = list(matching_points_3.index)\n",
    "            matching_indexes_all = matching_indexes_3.copy()\n",
    "            case = 3\n",
    "        elif df1['speech'].str.contains(match_4).any():\n",
    "            matching_points_4 = df1[df1[\"speech\"].str.contains(match_4)]\n",
    "            matching_indexes_4 = list(matching_points_4.index)\n",
    "            matching_indexes_all = matching_indexes_4.copy() \n",
    "            case = 4\n",
    "\n",
    "        # If we have at least one match, substitute 'Q: ' with the name of the attorney\n",
    "        if case != 0:\n",
    "            questioners = list()\n",
    "            for i in range(0, len(matching_indexes_all)):\n",
    "                Q_name = df1.iloc[matching_indexes_all[i], 1].split(\"BY \")[1]\n",
    "                questioners.append(Q_name)\n",
    "                if i < (len(matching_indexes_all)-1):\n",
    "                    for row in range(matching_indexes_all[i], matching_indexes_all[i + 1]):\n",
    "                        if df1.iloc[row, 0] == '#Q: ':\n",
    "                            df1.iloc[row, df1.columns.get_loc('person')] = Q_name\n",
    "                else:\n",
    "                    for row in range(matching_indexes_all[i], nrow):\n",
    "                        if df1.iloc[row, 0] == '#Q: ':\n",
    "                            df1.iloc[row, df1.columns.get_loc('person')] = Q_name\n",
    "        \n",
    "        # Append the df of each file under the previous one\n",
    "        df = df.append(df1, ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('January.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if df['person'].str.contains('#Q:').any():\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>speech</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>#THE COURT:</td>\n",
       "      <td>PEOPLE'S 126 AND 127.\\n</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>MR. DARDEN:\\n</td>\n",
       "      <td>BY MR. DARDEN: SHOWING YOU PEOPLE'S 126,DETECT...</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>MR. DARDEN:\\n</td>\n",
       "      <td>BY MR. DARDEN: WHAT IS SHOWN IN THATPHOTOGRAPH...</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>[VANNATTER,]</td>\n",
       "      <td>THAT'S A PORTION OF THE DEFENDANT'S BEDROOMSHO...</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>MR. DARDEN:\\n</td>\n",
       "      <td>AND 127, WHAT'S SHOWN THERE?\\n</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>#THE COURT:</td>\n",
       "      <td>ADMISSION.\\n</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>#MR. SHAPIRO:</td>\n",
       "      <td>AS TO HIS FEELINGS FOR PAULA?\\n</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>#THE COURT:</td>\n",
       "      <td>NO, NO. HIS FEELINGS FOR PAULA, HISAMBIVALENCE...</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>#MR. DARDEN:</td>\n",
       "      <td>DOES THAT HURT YOU?\\n</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>#MR. COCHRAN:</td>\n",
       "      <td>I MEAN, IT WAS ALSO LEADING ANDSUGGESTIVE WHEN...</td>\n",
       "      <td>MARCH 21, 1995</td>\n",
       "      <td>9:27 A.M.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              person                                             speech  \\\n",
       "1500    #THE COURT:                             PEOPLE'S 126 AND 127.\\n   \n",
       "1501   MR. DARDEN:\\n  BY MR. DARDEN: SHOWING YOU PEOPLE'S 126,DETECT...   \n",
       "1502   MR. DARDEN:\\n  BY MR. DARDEN: WHAT IS SHOWN IN THATPHOTOGRAPH...   \n",
       "1503    [VANNATTER,]  THAT'S A PORTION OF THE DEFENDANT'S BEDROOMSHO...   \n",
       "1504   MR. DARDEN:\\n                     AND 127, WHAT'S SHOWN THERE?\\n   \n",
       "...              ...                                                ...   \n",
       "2441    #THE COURT:                                        ADMISSION.\\n   \n",
       "2442  #MR. SHAPIRO:                     AS TO HIS FEELINGS FOR PAULA?\\n   \n",
       "2443    #THE COURT:   NO, NO. HIS FEELINGS FOR PAULA, HISAMBIVALENCE...   \n",
       "2444   #MR. DARDEN:                               DOES THAT HURT YOU?\\n   \n",
       "2445  #MR. COCHRAN:   I MEAN, IT WAS ALSO LEADING ANDSUGGESTIVE WHEN...   \n",
       "\n",
       "                 date       time  \n",
       "1500  MARCH 21, 1995   9:27 A.M.  \n",
       "1501  MARCH 21, 1995   9:27 A.M.  \n",
       "1502  MARCH 21, 1995   9:27 A.M.  \n",
       "1503  MARCH 21, 1995   9:27 A.M.  \n",
       "1504  MARCH 21, 1995   9:27 A.M.  \n",
       "...               ...        ...  \n",
       "2441  MARCH 21, 1995   9:27 A.M.  \n",
       "2442  MARCH 21, 1995   9:27 A.M.  \n",
       "2443  MARCH 21, 1995   9:27 A.M.  \n",
       "2444  MARCH 21, 1995   9:27 A.M.  \n",
       "2445  MARCH 21, 1995   9:27 A.M.  \n",
       "\n",
       "[946 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1500:2446,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "72cf7670dc092630df60de9903f582c8b72932f48b23b3a11c782c6b6b437cc5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "72cf7670dc092630df60de9903f582c8b72932f48b23b3a11c782c6b6b437cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
