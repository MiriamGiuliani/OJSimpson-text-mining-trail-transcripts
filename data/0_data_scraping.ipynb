{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code used for scraping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text transcripts of the trial are stored in the following website: http://simpson.walraven.org\n",
    "\n",
    "The content is organized by date, in 5 folders, one for each of the months in which the trial took place. In this project, the text analyzed is the one of the __Criminal Trial Trial Transcripts__, ignoring the content of the _juror interviews_, _motions and court orders_, the _preliminary hearings_, the _grand jury proceedings_ and the _Civil Trial_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every month has a different URL (folder) containing the corresponding transcripts\n",
    "urls = ['http://simpson.walraven.org/oj-feb.html',\n",
    "        'http://simpson.walraven.org/oj-mar.html', \n",
    "        'http://simpson.walraven.org/oj-apr.html',\n",
    "        'http://simpson.walraven.org/oj-may.html',\n",
    "        'http://simpson.walraven.org/oj-jun.html',\n",
    "        'http://simpson.walraven.org/oj-jul.html',\n",
    "        'http://simpson.walraven.org/oj-aug.html',\n",
    "        'http://simpson.walraven.org/oj-sep.html']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraping has been done for each month separately, to have a better control on the content. In the following cells, an example is given for the month of __January__. The same code has been used for the other months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"jan11.html\">January 11</a>,\n",
       " <a href=\"jan12.html\">January 12</a>,\n",
       " <a href=\"jan13.html\">January 13</a>,\n",
       " <a href=\"jan23.html\">January 23</a>,\n",
       " <a href=\"jan24.html\">January 24</a>,\n",
       " <a href=\"jan25.html\">January 25</a>,\n",
       " <a href=\"jan26.html\">January 26</a>,\n",
       " <a href=\"jan30.html\">January 30</a>,\n",
       " <a href=\"jan31.html\">January 31</a>,\n",
       " <a href=\"index.html\">previous</a>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://simpson.walraven.org/oj-jan.html'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jan11.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve one of the links as an example\n",
    "one_a_tag = soup.findAll(\"a\")[0]\n",
    "link = one_a_tag[\"href\"]\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing the following cells, the content of the link defined above is retrieved and saved as a _txt_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://simpson.walraven.org/jan11.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_url = 'http://simpson.walraven.org/'+ link\n",
    "download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./jan11.html.txt', <http.client.HTTPMessage at 0x676adf0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(download_url,'./'+link[link.find('/t_')+1:]+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing the following cell, a loop is initiated to retrieve and save the content of all the links for the month of January. Adding another level to the loop, one could retrieve all the content of the trial, iterating across all the months. \n",
    "\n",
    "A different file is saved for each day of the trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the whole data set, let's do a for loop through all a tags\n",
    "line_count = 0 # variable to track what line you are on\n",
    "for one_a_tag in soup.findAll('a'):  #'a' tags are for links\n",
    "    if line_count < 19: # code for text files starts at line 36\n",
    "        link = one_a_tag['href']\n",
    "        download_url = 'http://simpson.walraven.org/'+ link\n",
    "        urllib.request.urlretrieve(download_url,'./'+link[link.find('/turnstile_')+1:]+'.txt') \n",
    "        time.sleep(1) # pause the code for a sec\n",
    "    # add 1 for next line\n",
    "    line_count +=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72cf7670dc092630df60de9903f582c8b72932f48b23b3a11c782c6b6b437cc5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "72cf7670dc092630df60de9903f582c8b72932f48b23b3a11c782c6b6b437cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
